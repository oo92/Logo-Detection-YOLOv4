{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LOL_Darknet_Roboflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDTvGt2zt7cm"
      },
      "source": [
        "#### **Configuring cuDNN on Colab for YOLOv4**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Guw9wew5JSZ",
        "outputId": "22f42fae-daf3-4f11-b049-788bc90858c5"
      },
      "source": [
        "# Change the number depending on what GPU is listed above, under NVIDIA-SMI > Name.\n",
        "# Tesla K80: 30\n",
        "# Tesla P100: 60\n",
        "# Tesla T4: 75\\\n",
        "%env compute_capability=60"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: compute_capability=60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16pvdFMa1FEe"
      },
      "source": [
        "#### **Installing Darknet for YOLOv4 on Colab**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyMBDkaL-Aep"
      },
      "source": [
        "%cd /content/\n",
        "%rm -rf darknet sample_data/\n",
        "\n",
        "#we clone the fork of darknet maintained by roboflow\n",
        "#small changes have been made to configure darknet for training\n",
        "!git clone https://github.com/AlexeyAB/darknet.git\n",
        "\n",
        "#install environment from the Makefile\n",
        "%cd darknet/\n",
        "# compute_30, sm_30 for Tesla K80\n",
        "# compute_75, sm_75 for Tesla T4\n",
        "# !sed -i 's/ARCH= -gencode arch=compute_60,code=sm_60/ARCH= -gencode arch=compute_30,code=sm_30/g' Makefile\n",
        " \n",
        "#install environment from the Makefile\n",
        "#note if you are on Colab Pro this works on a P100 GPU\n",
        "#if you are on Colab free, you may need to change the Makefile for the K80 GPU\n",
        "#this goes for any GPU, you need to change the Makefile to inform darknet which GPU you are running on.\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
        " \n",
        "#for GPU accelerated training\n",
        "!sed -i 's/GPU=0/GPU=1/g' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n",
        "!sed -i \"s/ARCH= -gencode arch=compute_75,code=sm_75/ARCH= -gencode arch=compute_${compute_capability},code=sm_${compute_capability}/g\" Makefile\n",
        "!make\n",
        "\n",
        "%cd /content/darknet\n",
        "\n",
        "# YOLOv4\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWOiKj37l4wW"
      },
      "source": [
        "#### **Set up Custom Dataset for YOLOv4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2u5_H7Jz06a"
      },
      "source": [
        "I have uploaded all the training and test images into my Google Drive. The cells below assemble the dataset to be compatible with the YOLO format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MF1xRXd94vo"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62IFFOwj05N6"
      },
      "source": [
        "%cd /content\n",
        "!mkdir /content/darknet/prediction-images\n",
        "!mkdir /content/darknet/data/obj\n",
        "\n",
        "!unzip /content/drive/MyDrive/worlds-lec-dataset.zip -d /content/darknet/logorec/\n",
        "!unzip /content/drive/MyDrive/youtube_images.zip -d /content/darknet/logorec/\n",
        "\n",
        "!cp /content/drive/MyDrive/worlds-test-video.mp4 /content/darknet/\n",
        "!cp /content/drive/MyDrive/lec-test-video.mp4 /content/darknet\n",
        "\n",
        "%cat /content/darknet/logorec/Worlds-LEC-Dataset/classes.txt | cut -d\" \" -f2 | cut -d\".\" -f1 >> /content/darknet/data/obj.names\n",
        "\n",
        "%cd /content/\n",
        "!rm -rf /content/weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiCILEbs1NII",
        "outputId": "3e39e15c-fac5-48fe-be68-8bcb5cfac199"
      },
      "source": [
        "import os\n",
        "from random import sample\n",
        "\n",
        "trainshare = 0.8\n",
        "\n",
        "#Set up training file directories for custom dataset\n",
        "%cd /content/darknet/\n",
        "\n",
        "#copy image and labels\n",
        "%cp /content/darknet/logorec/Worlds-LEC-Dataset/*.png data/obj/\n",
        "%cp /content/darknet/logorec/Worlds-LEC-Dataset/*.txt data/obj/\n",
        "\n",
        "with open('data/obj.data', 'w') as out:\n",
        "  out.write(f'classes = 13\\n')\n",
        "  out.write('train = data/train.txt\\n')\n",
        "  out.write('valid = data/valid.txt\\n')\n",
        "  out.write('names = data/obj.names\\n')\n",
        "  out.write('backup = backup/')\n",
        " \n",
        "#write train file (just the image list)\n",
        "files = [f for f in os.listdir('data/obj/') if f.endswith('png')]\n",
        "train = sample(files, int(len(files) * trainshare))\n",
        "validation = set(files) - set(train)\n",
        "\n",
        "with open('data/train.txt', 'w') as out:\n",
        "  for img in train:\n",
        "    out.write('data/obj/' + img + '\\n')\n",
        " \n",
        "#write the valid file (just the image list)\n",
        "with open('data/valid.txt', 'w') as out:\n",
        "  for img in validation:\n",
        "    out.write('data/obj/' + img + '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/darknet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HtRqO3QvjkP"
      },
      "source": [
        "#### **Write Custom Training Config for YOLOv4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_WJcqHhpeVr"
      },
      "source": [
        "#we build config dynamically based on number of classes\n",
        "#we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg\n",
        "def file_len(fname):\n",
        "  with open(fname) as f:\n",
        "    for i, l in enumerate(f):\n",
        "      pass\n",
        "  return i + 1\n",
        "\n",
        "num_classes = file_len('data/obj.names')\n",
        "max_batches = num_classes*2000\n",
        "steps1 = .8 * max_batches\n",
        "steps2 = .9 * max_batches\n",
        "steps_str = str(steps1)+','+str(steps2)\n",
        "num_filters = (num_classes + 5) * 3\n",
        " \n",
        "print(\"writing config for a custom YOLOv4 detector detecting number of classes: \" + str(num_classes))\n",
        " \n",
        "#Instructions from the darknet repo\n",
        "#change line max_batches to (classes*2000 but not less than number of training images, and not less than 6000), f.e. max_batches=6000 if you train for 3 classes\n",
        "#change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\n",
        "if os.path.exists('./cfg/custom-yolov4-detector.cfg'): \n",
        "  os.remove('./cfg/custom-yolov4-detector.cfg')\n",
        " \n",
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        " \n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnM2Z-NTitl_"
      },
      "source": [
        "%%writetemplate ./cfg/custom-yolov4-detector.cfg\n",
        "\n",
        "[net]\n",
        "# Testing\n",
        "#batch=1\n",
        "#subdivisions=1\n",
        "# Training\n",
        "batch=64\n",
        "subdivisions=32\n",
        "width=512\n",
        "height=512\n",
        "channels=3\n",
        "momentum=0.949\n",
        "decay=0.0005\n",
        "angle=0\n",
        "saturation = 1.5\n",
        "exposure = 1.5\n",
        "hue=.1\n",
        "\n",
        "learning_rate=0.001\n",
        "burn_in=1000\n",
        "max_batches = {max_batches}\n",
        "policy=steps\n",
        "steps=400000,450000\n",
        "scales=.1,.1\n",
        "\n",
        "#cutmix=1\n",
        "mosaic=1\n",
        "\n",
        "#:104x104 54:52x52 85:26x26 104:13x13 for 416\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[route]\n",
        "layers = -1,-7\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "# Downsample\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[route]\n",
        "layers = -1,-10\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[route]\n",
        "layers = -1,-28\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[route]\n",
        "layers = -1,-28\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=1024\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "\n",
        "[route]\n",
        "layers = -1,-16\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=1024\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=mish\n",
        "stopbackward=1\n",
        "\n",
        "##########################\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=1024\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "### SPP ###\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=5\n",
        "\n",
        "[route]\n",
        "layers=-2\n",
        "\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=9\n",
        "\n",
        "[route]\n",
        "layers=-4\n",
        "\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=13\n",
        "\n",
        "[route]\n",
        "layers=-1,-3,-5,-6\n",
        "### End SPP ###\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=1024\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = 85\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1, -3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=512\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=512\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = 54\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1, -3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "##########################\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "\n",
        "[yolo]\n",
        "mask = 0,1,2\n",
        "anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\n",
        "classes={num_classes}\n",
        "num=9\n",
        "jitter=.3\n",
        "ignore_thresh = .9 \n",
        "iou_normalizer=0.5 \n",
        "iou_loss=giou\n",
        "truth_thresh = 1\n",
        "scale_x_y = 1.2\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "max_delta=5\n",
        "\n",
        "\n",
        "[route]\n",
        "layers = -4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "filters=256\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1, -16\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=512\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=512\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=512\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "\n",
        "[yolo]\n",
        "mask = 3,4,5\n",
        "anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\n",
        "classes={num_classes}\n",
        "num=9\n",
        "jitter=.3\n",
        "ignore_thresh = .9 \n",
        "iou_normalizer=0.5 \n",
        "iou_loss=giou\n",
        "truth_thresh = 1\n",
        "scale_x_y = 1.1\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "max_delta=5\n",
        "\n",
        "\n",
        "[route]\n",
        "layers = -4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "filters=512\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1, -37\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=1024\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=1024\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=1024\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[yolo]\n",
        "mask = 6,7,8\n",
        "anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\n",
        "classes={num_classes}\n",
        "num=9\n",
        "jitter=.3\n",
        "ignore_thresh = .9 \n",
        "iou_normalizer=0.5 \n",
        "iou_loss=giou\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "max_delta=5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2LAciMh4Cut"
      },
      "source": [
        "#here is the file that was just written. \n",
        "#you may consider adjusting certain things\n",
        " \n",
        "#like the number of subdivisions 64 runs faster but Colab GPU may not be big enough\n",
        "#if Colab GPU memory is too small, you will need to adjust subdivisions to 16\n",
        "%cat /content/darknet/cfg/custom-yolov4-detector.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWrG9EGamSpH"
      },
      "source": [
        "#### **Train Custom YOLOv4 Detector**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6miYFbvExqMd"
      },
      "source": [
        "# Train from scratch\n",
        "!./darknet detector train data/obj.data cfg/custom-yolov4-detector.cfg yolov4.conv.137 -dont_show -map -clear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBnwpBV5ZXxQ"
      },
      "source": [
        "#### **Running an inference on test videos and images with Saved YOLOv4 Weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5SDDsZ8QBrd"
      },
      "source": [
        "%cd /content\n",
        "\n",
        "!zip -r /content/drive/MyDrive/worlds-lec-dataset.zip /content/darknet/logorec/Worlds-LEC-Dataset\n",
        "!zip -r /content/drive/MyDrive/youtube_images.zip /content/darknet/logorec/youtube_images\n",
        "\n",
        "!cp /content/darknet/worlds-test-video.mp4 /content/drive/MyDrive/ \n",
        "!cp /content/darknet/lec-test-video.mp4 /content/drive/MyDrive/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzoJQQw8Zdco"
      },
      "source": [
        "#define utility function\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        " \n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        " \n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3dJB6NZv4kh"
      },
      "source": [
        "#check if weigths have saved yet\n",
        "#backup houses the last weights for our detector\n",
        "#(file yolo-obj_last.weights will be saved to the build\\darknet\\x64\\backup\\ for each 100 iterations)\n",
        "#(file yolo-obj_xxxx.weights will be saved to the build\\darknet\\x64\\backup\\ for each 1000 iterations)\n",
        "#After training is complete - get result yolo-obj_final.weights from path build\\darknet\\x64\\bac\n",
        "!ls /content/darknet/backup\n",
        "#if it is empty you haven't trained for long enough yet, you need to train for at least 100 iterations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-_E3O5Mf4Mf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36bbc9cd-a3be-462a-fb1f-973e236bfd5f"
      },
      "source": [
        "#coco.names is hardcoded somewhere in the detector\n",
        "%cd /content/darknet/\n",
        "%cp data/obj.names data/coco.names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/darknet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z98b_WY_4oWP"
      },
      "source": [
        "#### **The cell below runs an inference on every single test image in the test folder.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca6XRKBeQZ3p"
      },
      "source": [
        "import random, os, shutil\n",
        "\n",
        "#/test has images that we can test our detector on\n",
        "test_folder = \"/content/darknet/logorec/youtube_images/\"\n",
        "test_images = [f for f in os.listdir(test_folder) if f.endswith('.png')]\n",
        "img_path = ''\n",
        "counter = 0\n",
        "\n",
        "for i in range(0, len(test_images)):\n",
        "  img_path = test_folder + test_images[i];\n",
        "  !./darknet detect cfg/custom-yolov4-detector.cfg backup/custom-yolov4-detector_best.weights {img_path} -dont-show\n",
        "  imShow('predictions.jpg')\n",
        "  src_dir='/content/darknet/predictions.jpg'\n",
        "  dst_dir='/content/darknet/prediction-images/prediction-'+str(counter)+\".jpg\"\n",
        "  shutil.copy(src_dir,dst_dir)\n",
        "  counter += 1\n",
        "\n",
        "%cd /content/darknet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A46lr3Z43_i"
      },
      "source": [
        "#### **Saving the weights, the config files, the charts and the prediction images to the drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ejH24D6JSu8u"
      },
      "source": [
        "!mkdir /content/darknet/training_results\n",
        "\n",
        "# Creating the readme file\n",
        "!touch /content/darknet/training_results/readme.txt\n",
        "!echo \"The training set was trained on YOLOv4's default weights with a distractor set\" >> /content/darknet/training_results/readme.txt\n",
        "\n",
        "# Moving the chart to the results directory\n",
        "!cp /content/darknet/chart* /content/darknet/training_results\n",
        "\n",
        "# Moving the config file to the results directory\n",
        "!cp /content/darknet/cfg/custom-yolov4-detector.cfg /content/darknet/training_results\n",
        "\n",
        "# Maving the obj.names and obj.data files to the results directory\n",
        "!cp /content/darknet/data/obj.* /content/darknet/training_results\n",
        "\n",
        "# Moving the weights to the results directory\n",
        "!cp /content/darknet/backup/*.weights /content/darknet/training_results\n",
        "\n",
        "# Moving the predicted images to the results directory  \n",
        "!cp -r /content/darknet/prediction-images /content/darknet/training_results\n",
        "\n",
        "# Zip the training result files and copy to the drive\n",
        "!zip -r march13_results.zip /content/darknet/training_results\n",
        "!cp march13_results.zip /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okLaLRX55Pa8"
      },
      "source": [
        "#### **Running darknet detector on the test videos and saving the resulting video files to the drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yDDLldWbTGfe"
      },
      "source": [
        "# Run a test inference for the worlds and LEC event videos\n",
        "!./darknet detector demo data/obj.data cfg/custom-yolov4-tiny-detector.cfg backup/custom-yolov4-tiny-detector_best.weights /content/darknet/worlds-test-video.mp4 -dont_show -thresh 0.25 -out_filename /content/RESULT_worlds-test.mp4\n",
        "!cp /content/RESULT_LEC-test.mp4 /content/drive/MyDrive/\n",
        "\n",
        "!./darknet detector demo data/obj.data cfg/custom-yolov4-tiny-detector.cfg backup/custom-yolov4-tiny-detector_best.weights /content/darknet/lec-test-video.mp4 -dont_show -thresh 0.25 -out_filename /content/RESULT_LEC-test.mp4\n",
        "!cp /content/RESULT_worlds-test.mp4 /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}